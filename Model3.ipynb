{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os, cv, math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import Augmentor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'test_set', 'training_set', 'U', 'V', 'validation_set', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'asl_dataset_augmented'\n",
    "dataset_list = os.listdir(dataset_path)\n",
    "print(dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Executing Pipeline:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 205 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\0\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=100x100 at 0x23BB4D4B6D8>: 100%|██████████| 300/300 [00:01<00:00, 151.81 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 206 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\1\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=100x100 at 0x23BB4DF72B0>: 100%|██████████| 300/300 [00:02<00:00, 133.76 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 206 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\2\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=100x100 at 0x23BB4C6F630>: 100%|██████████| 300/300 [00:02<00:00, 123.02 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 206 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\3\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=100x100 at 0x23BB4DBC7F0>: 100%|██████████| 300/300 [00:02<00:00, 114.15 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 207 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\4\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=100x100 at 0x23BB4DCB550>: 100%|██████████| 300/300 [00:02<00:00, 108.58 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 207 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\5\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=100x100 at 0x23BB4DD6EF0>: 100%|██████████| 300/300 [00:02<00:00, 114.68 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 207 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\6\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=100x100 at 0x23BB4D1FE80>: 100%|██████████| 300/300 [00:02<00:00, 143.34 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 206 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\7\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=100x100 at 0x23BB4DEB4E0>: 100%|██████████| 300/300 [00:02<00:00, 140.44 Samples/s] \n",
      "Processing <PIL.Image.Image image mode=RGB size=100x100 at 0x23BB4DC8518>:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 208 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\8\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=100x100 at 0x23BB4DC8748>: 100%|██████████| 300/300 [00:02<00:00, 129.13 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 204 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\9\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=100x100 at 0x23BB4DD6668>: 100%|██████████| 300/300 [00:02<00:00, 111.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB5E5FB00>:   1%|          | 2/300 [00:00<00:35,  8.31 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\A\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D87A90>: 100%|██████████| 300/300 [00:00<00:00, 308.16 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4DF6208>:   1%|▏         | 4/300 [00:00<00:31,  9.30 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\B\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4DC86A0>: 100%|██████████| 300/300 [00:00<00:00, 317.92 Samples/s]                 \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4DEDBE0>:   1%|          | 3/300 [00:00<00:30,  9.76 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\C\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D15470>: 100%|██████████| 300/300 [00:00<00:00, 330.67 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4DC8C88>:   2%|▏         | 5/300 [00:00<00:10, 29.35 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\D\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4C698D0>: 100%|██████████| 300/300 [00:00<00:00, 311.51 Samples/s]                  \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4CF3588>:   0%|          | 0/300 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\del\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D01748>: 100%|██████████| 300/300 [00:00<00:00, 300.07 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4DE3358>:   1%|          | 3/300 [00:00<00:31,  9.32 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\E\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D4BE80>: 100%|██████████| 300/300 [00:00<00:00, 302.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D0EF60>:   1%|          | 2/300 [00:00<00:38,  7.72 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\F\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4E09390>: 100%|██████████| 300/300 [00:01<00:00, 296.85 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D044E0>:   1%|          | 2/300 [00:00<00:42,  7.01 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\G\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4C47C88>: 100%|██████████| 300/300 [00:00<00:00, 373.17 Samples/s]                 \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4CF3668>:   0%|          | 1/300 [00:00<00:52,  5.67 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\H\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4E1A940>: 100%|██████████| 300/300 [00:00<00:00, 302.13 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D13D68>:   1%|▏         | 4/300 [00:00<00:37,  7.92 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\I\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4DE3AC8>: 100%|██████████| 300/300 [00:00<00:00, 337.54 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D4B8D0>:   0%|          | 1/300 [00:00<00:54,  5.45 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\J\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D80EF0>: 100%|██████████| 300/300 [00:01<00:00, 297.79 Samples/s]                 \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4DE3198>:   1%|▏         | 4/300 [00:00<00:35,  8.27 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\K\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4C695C0>: 100%|██████████| 300/300 [00:00<00:00, 332.99 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D05550>:   2%|▏         | 5/300 [00:00<00:11, 25.71 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\L\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D98AC8>: 100%|██████████| 300/300 [00:00<00:00, 336.67 Samples/s]                  \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4CECA20>:   1%|▏         | 4/300 [00:00<00:37,  7.82 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\M\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D804A8>: 100%|██████████| 300/300 [00:00<00:00, 334.27 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4CF69E8>:   1%|          | 3/300 [00:00<00:31,  9.55 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\N\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4CF3EF0>: 100%|██████████| 300/300 [00:00<00:00, 314.71 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D2F278>:   1%|▏         | 4/300 [00:00<00:43,  6.79 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\nothing\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D141D0>: 100%|██████████| 300/300 [00:00<00:00, 360.08 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D10780>:   2%|▏         | 6/300 [00:00<00:15, 18.88 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\O\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D98C18>: 100%|██████████| 300/300 [00:00<00:00, 310.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB5E438D0>:   1%|          | 3/300 [00:00<00:33,  8.92 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\P\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D98320>: 100%|██████████| 300/300 [00:00<00:00, 312.13 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D0DE10>:   0%|          | 1/300 [00:00<00:51,  5.84 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\Q\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D1EBE0>: 100%|██████████| 300/300 [00:00<00:00, 325.73 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4DE3940>:   1%|▏         | 4/300 [00:00<00:31,  9.49 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\R\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D1EC50>: 100%|██████████| 300/300 [00:00<00:00, 309.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4C69198>:   2%|▏         | 5/300 [00:00<00:15, 18.57 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\S\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D4B208>: 100%|██████████| 300/300 [00:00<00:00, 331.39 Samples/s]                 \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4C7D2E8>:   2%|▏         | 6/300 [00:00<00:14, 19.96 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\space\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D14198>: 100%|██████████| 300/300 [00:00<00:00, 362.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4CFF5F8>:   2%|▏         | 5/300 [00:00<00:10, 26.97 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\T\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4C7DA58>: 100%|██████████| 300/300 [00:00<00:00, 318.96 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D0F940>:   0%|          | 1/300 [00:00<00:39,  7.57 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\U\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4C69588>: 100%|██████████| 300/300 [00:01<00:00, 264.52 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D10DA0>:   4%|▎         | 11/300 [00:00<00:04, 67.29 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\V\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D0DF98>: 100%|██████████| 300/300 [00:00<00:00, 411.08 Samples/s]                  \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4DE3668>:   1%|▏         | 4/300 [00:00<00:10, 27.86 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\W\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB5E43B38>: 100%|██████████| 300/300 [00:00<00:00, 312.76 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D0EB38>:   1%|▏         | 4/300 [00:00<00:14, 19.95 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\X\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D1EBA8>: 100%|██████████| 300/300 [00:00<00:00, 302.99 Samples/s]                  \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x23BB4D2F978>:   1%|          | 2/300 [00:00<00:29, 10.00 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\Y\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4CFF710>: 100%|██████████| 300/300 [00:00<00:00, 353.68 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4DF8EB8>:   3%|▎         | 8/300 [00:00<00:08, 35.66 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 300 image(s) found.\n",
      "Output directory set to asl_dataset_augmented\\Z\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x23BB4D80550>: 100%|██████████| 300/300 [00:01<00:00, 285.69 Samples/s]                  \n"
     ]
    }
   ],
   "source": [
    "training_path = dataset_path\n",
    "for i in dataset_list:\n",
    "    p = Augmentor.Pipeline(os.path.join(training_path, i))\n",
    "    p.zoom(probability=0.5, min_factor=1.1, max_factor=1.3)\n",
    "    p.sample(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = {}\n",
    "validation_set = {}\n",
    "test_set = {}\n",
    "\n",
    "for cat in os.listdir(dataset_path):\n",
    "    cat_dir = os.path.join(dataset_path, cat, 'output')\n",
    "    cat_files = os.listdir(cat_dir)\n",
    "    train_list, test_list = train_test_split(cat_files, test_size=0.3)\n",
    "    validation_list, test_list = train_test_split(test_list, test_size=0.5)\n",
    "    \n",
    "    train_set[cat] = train_list\n",
    "    test_set[cat] = test_list\n",
    "    validation_set[cat] = validation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [02:59<00:00,  4.59s/it]\n"
     ]
    }
   ],
   "source": [
    "for cat in tqdm(train_set.keys()):\n",
    "    cat_dir = os.path.join(dataset_path, 'training_set', 'class_' + str(cat))\n",
    "    os.makedirs(cat_dir)\n",
    "    for file in train_set[cat]:\n",
    "        src = os.path.join(dataset_path, cat, 'output', file)\n",
    "        dest = os.path.join(cat_dir, file)\n",
    "        copyfile(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:33<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for cat in tqdm(validation_set.keys()):\n",
    "    cat_dir = os.path.join(dataset_path, 'validation_set', 'class_' + str(cat))\n",
    "    os.makedirs(cat_dir)\n",
    "    for file in validation_set[cat]:\n",
    "        src = os.path.join(dataset_path, cat,'output', file)\n",
    "        dest = os.path.join(cat_dir, file)\n",
    "        copyfile(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:28<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for cat in tqdm(test_set.keys()):\n",
    "    cat_dir = os.path.join(dataset_path, 'test_set', 'class_' + str(cat))\n",
    "    os.makedirs(cat_dir)\n",
    "    for file in test_set[cat]:\n",
    "        src = os.path.join(dataset_path, cat,'output', file)\n",
    "        dest = os.path.join(cat_dir, file)\n",
    "        copyfile(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0- Training size: 210 Validation set: 45 Test set: 45\n",
      "1- Training size: 210 Validation set: 45 Test set: 45\n",
      "2- Training size: 210 Validation set: 45 Test set: 45\n",
      "3- Training size: 210 Validation set: 45 Test set: 45\n",
      "4- Training size: 210 Validation set: 45 Test set: 45\n",
      "5- Training size: 210 Validation set: 45 Test set: 45\n",
      "6- Training size: 210 Validation set: 45 Test set: 45\n",
      "7- Training size: 210 Validation set: 45 Test set: 45\n",
      "8- Training size: 210 Validation set: 45 Test set: 45\n",
      "9- Training size: 210 Validation set: 45 Test set: 45\n",
      "A- Training size: 210 Validation set: 45 Test set: 45\n",
      "B- Training size: 210 Validation set: 45 Test set: 45\n",
      "C- Training size: 210 Validation set: 45 Test set: 45\n",
      "D- Training size: 210 Validation set: 45 Test set: 45\n",
      "del- Training size: 210 Validation set: 45 Test set: 45\n",
      "E- Training size: 210 Validation set: 45 Test set: 45\n",
      "F- Training size: 210 Validation set: 45 Test set: 45\n",
      "G- Training size: 210 Validation set: 45 Test set: 45\n",
      "H- Training size: 210 Validation set: 45 Test set: 45\n",
      "I- Training size: 210 Validation set: 45 Test set: 45\n",
      "J- Training size: 210 Validation set: 45 Test set: 45\n",
      "K- Training size: 210 Validation set: 45 Test set: 45\n",
      "L- Training size: 210 Validation set: 45 Test set: 45\n",
      "M- Training size: 210 Validation set: 45 Test set: 45\n",
      "N- Training size: 210 Validation set: 45 Test set: 45\n",
      "nothing- Training size: 210 Validation set: 45 Test set: 45\n",
      "O- Training size: 210 Validation set: 45 Test set: 45\n",
      "P- Training size: 210 Validation set: 45 Test set: 45\n",
      "Q- Training size: 210 Validation set: 45 Test set: 45\n",
      "R- Training size: 210 Validation set: 45 Test set: 45\n",
      "S- Training size: 210 Validation set: 45 Test set: 45\n",
      "space- Training size: 210 Validation set: 45 Test set: 45\n",
      "T- Training size: 210 Validation set: 45 Test set: 45\n",
      "U- Training size: 210 Validation set: 45 Test set: 45\n",
      "V- Training size: 210 Validation set: 45 Test set: 45\n",
      "W- Training size: 210 Validation set: 45 Test set: 45\n",
      "X- Training size: 210 Validation set: 45 Test set: 45\n",
      "Y- Training size: 210 Validation set: 45 Test set: 45\n",
      "Z- Training size: 210 Validation set: 45 Test set: 45\n"
     ]
    }
   ],
   "source": [
    "for i in train_set.keys():\n",
    "    print(i+ \"- Training size: \"+ str(len(train_set[i]))+ \" Validation set: \"+ str(len(validation_set[i]))+ \" Test set: \"+ str(len(test_set[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8190 images belonging to 39 classes.\n",
      "Found 1755 images belonging to 39 classes.\n",
      "Found 1755 images belonging to 39 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_data = train_datagen.flow_from_directory(os.path.join(dataset_path, 'training_set'),\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "validation_data = validation_datagen.flow_from_directory(os.path.join(dataset_path, 'validation_set'),\n",
    "                                            target_size = (64,64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(os.path.join(dataset_path, 'test_set'),\n",
    "                                            target_size = (64,64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (64,64,3), activation= 'relu'))\n",
    "BatchNormalization()\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "BatchNormalization()\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 39, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "176/256 [===================>..........] - ETA: 20s - loss: 3.6101 - acc: 0.0380"
     ]
    }
   ],
   "source": [
    "history = classifier.fit_generator(training_data,\n",
    "                                  steps_per_epoch= math.ceil(training_data.n/training_data.batch_size),\n",
    "                                  epochs=50,\n",
    "                                  validation_data= validation_data,\n",
    "                                  validation_steps= math.ceil(validation_data.n/validation_data.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
