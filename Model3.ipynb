{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, cv, math\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import Augmentor\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'test_set', 'training_set', 'U', 'V', 'validation_set', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'asl_dataset_augmented'\n",
    "dataset_list = os.listdir(dataset_path)\n",
    "print(dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\A\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x205990D5710>: 100%|██████████| 100/100 [00:00<00:00, 108.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x2059914CEF0>:   2%|▏         | 2/100 [00:00<00:14,  6.58 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\B\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x20599690518>: 100%|██████████| 100/100 [00:00<00:00, 183.59 Samples/s]                \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x20599693160>:   1%|          | 1/100 [00:00<00:15,  6.23 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\C\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x20598F1B358>: 100%|██████████| 100/100 [00:00<00:00, 215.47 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\D\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x205996A56D8>: 100%|██████████| 100/100 [00:00<00:00, 134.96 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x20598F1B198>:   1%|          | 1/100 [00:00<00:15,  6.42 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\del\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x205996B8F28>: 100%|██████████| 100/100 [00:00<00:00, 190.50 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\E\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x20599171550>: 100%|██████████| 100/100 [00:00<00:00, 144.44 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\F\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x20599690320>: 100%|██████████| 100/100 [00:00<00:00, 187.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\G\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x2059915BC88>: 100%|██████████| 100/100 [00:00<00:00, 190.01 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\H\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x20599159BE0>: 100%|██████████| 100/100 [00:00<00:00, 183.34 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\I\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x2059918FEF0>: 100%|██████████| 100/100 [00:00<00:00, 152.55 Samples/s]                \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x2059913E208>:   2%|▏         | 2/100 [00:00<00:14,  7.00 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\J\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x20599175C50>: 100%|██████████| 100/100 [00:00<00:00, 268.63 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\K\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x2059914C5C0>: 100%|██████████| 100/100 [00:00<00:00, 186.28 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\L\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x20599157400>: 100%|██████████| 100/100 [00:00<00:00, 179.91 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\M\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x205996A1400>: 100%|██████████| 100/100 [00:00<00:00, 193.05 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x2059915B048>:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\N\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x20599180DD8>: 100%|██████████| 100/100 [00:00<00:00, 190.44 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x2059914CEF0>:   2%|▏         | 2/100 [00:00<00:13,  7.15 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\nothing\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x20599181748>: 100%|██████████| 100/100 [00:00<00:00, 276.07 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\O\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x2059915B588>: 100%|██████████| 100/100 [00:00<00:00, 181.61 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\P\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x20599181908>: 100%|██████████| 100/100 [00:00<00:00, 181.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x2059914C978>:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\Q\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x205990E94A8>: 100%|██████████| 100/100 [00:00<00:00, 199.71 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\R\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x20599179E80>: 100%|██████████| 100/100 [00:00<00:00, 180.07 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\S\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x2059918FC50>: 100%|██████████| 100/100 [00:00<00:00, 180.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=200x200 at 0x205991657F0>:   1%|          | 1/100 [00:00<00:16,  6.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\space\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x205996A55F8>: 100%|██████████| 100/100 [00:00<00:00, 253.80 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\T\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x205996A1B38>: 100%|██████████| 100/100 [00:00<00:00, 174.55 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\U\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x20599181438>: 100%|██████████| 100/100 [00:00<00:00, 169.99 Samples/s]                \n",
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x20599171048>:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\V\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x20599171B38>: 100%|██████████| 100/100 [00:00<00:00, 191.18 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\W\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x2059918B198>: 100%|██████████| 100/100 [00:00<00:00, 180.34 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\X\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x205991750B8>: 100%|██████████| 100/100 [00:00<00:00, 184.00 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/100 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\Y\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=400x400 at 0x20599182400>: 100%|██████████| 100/100 [00:02<00:00, 36.91 Samples/s]                 \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x20599171A58>:   2%|▏         | 2/100 [00:00<00:10,  9.45 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 40 image(s) found.\n",
      "Output directory set to dataset\\Z\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x200 at 0x2059916E860>: 100%|██████████| 100/100 [00:00<00:00, 228.47 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "training_path = dataset_path\n",
    "for i in dataset_list:\n",
    "    p = Augmentor.Pipeline(os.path.join(training_path, i))\n",
    "    p.zoom(probability=0.5, min_factor=1.1, max_factor=1.3)\n",
    "    p.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = {}\n",
    "validation_set = {}\n",
    "test_set = {}\n",
    "\n",
    "for cat in dataset_list:\n",
    "    cat_dir = os.path.join(dataset_path, cat, 'output')\n",
    "    cat_files = os.listdir(cat_dir)\n",
    "    train_list, test_list = train_test_split(cat_files, test_size=0.3)\n",
    "    validation_list, test_list = train_test_split(test_list, test_size=0.5)\n",
    "    \n",
    "    train_set[cat] = train_list\n",
    "    test_set[cat] = test_list\n",
    "    validation_set[cat] = validation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [01:06<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "for cat in tqdm(train_set.keys()):\n",
    "    cat_dir = os.path.join(dataset_path, 'training_set', 'class_' + str(cat))\n",
    "    os.makedirs(cat_dir)\n",
    "    for file in train_set[cat]:\n",
    "        image = cv2.imread(os.path.join(dataset_path, cat, 'output', file))\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        src = cv2.Canny(blurred, 10, 100)\n",
    "        dest = os.path.join(cat_dir, file)\n",
    "        im = Image.fromarray(src)\n",
    "        im.save(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:15<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for cat in tqdm(validation_set.keys()):\n",
    "    cat_dir = os.path.join(dataset_path, 'validation_set', 'class_' + str(cat))\n",
    "    os.makedirs(cat_dir)\n",
    "    for file in validation_set[cat]:\n",
    "        image = cv2.imread(os.path.join(dataset_path, cat, 'output', file))\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        src = cv2.Canny(blurred, 10, 100)\n",
    "        dest = os.path.join(cat_dir, file)\n",
    "        im = Image.fromarray(src)\n",
    "        im.save(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:13<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for cat in tqdm(test_set.keys()):\n",
    "    cat_dir = os.path.join(dataset_path, 'test_set', 'class_' + str(cat))\n",
    "    os.makedirs(cat_dir)\n",
    "    for file in test_set[cat]:\n",
    "        image = cv2.imread(os.path.join(dataset_path, cat, 'output', file))\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        src = cv2.Canny(blurred, 10, 100)\n",
    "        dest = os.path.join(cat_dir, file)\n",
    "        im = Image.fromarray(src)\n",
    "        im.save(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A- Training size: 70 Validation set: 15 Test set: 15\n",
      "B- Training size: 70 Validation set: 15 Test set: 15\n",
      "C- Training size: 70 Validation set: 15 Test set: 15\n",
      "D- Training size: 70 Validation set: 15 Test set: 15\n",
      "del- Training size: 70 Validation set: 15 Test set: 15\n",
      "E- Training size: 70 Validation set: 15 Test set: 15\n",
      "F- Training size: 70 Validation set: 15 Test set: 15\n",
      "G- Training size: 70 Validation set: 15 Test set: 15\n",
      "H- Training size: 70 Validation set: 15 Test set: 15\n",
      "I- Training size: 70 Validation set: 15 Test set: 15\n",
      "J- Training size: 70 Validation set: 15 Test set: 15\n",
      "K- Training size: 70 Validation set: 15 Test set: 15\n",
      "L- Training size: 70 Validation set: 15 Test set: 15\n",
      "M- Training size: 70 Validation set: 15 Test set: 15\n",
      "N- Training size: 70 Validation set: 15 Test set: 15\n",
      "nothing- Training size: 70 Validation set: 15 Test set: 15\n",
      "O- Training size: 70 Validation set: 15 Test set: 15\n",
      "P- Training size: 70 Validation set: 15 Test set: 15\n",
      "Q- Training size: 70 Validation set: 15 Test set: 15\n",
      "R- Training size: 70 Validation set: 15 Test set: 15\n",
      "S- Training size: 70 Validation set: 15 Test set: 15\n",
      "space- Training size: 70 Validation set: 15 Test set: 15\n",
      "T- Training size: 70 Validation set: 15 Test set: 15\n",
      "U- Training size: 70 Validation set: 15 Test set: 15\n",
      "V- Training size: 70 Validation set: 15 Test set: 15\n",
      "W- Training size: 70 Validation set: 15 Test set: 15\n",
      "X- Training size: 70 Validation set: 15 Test set: 15\n",
      "Y- Training size: 70 Validation set: 15 Test set: 15\n",
      "Z- Training size: 70 Validation set: 15 Test set: 15\n"
     ]
    }
   ],
   "source": [
    "for i in train_set.keys():\n",
    "    print(i+ \"- Training size: \"+ str(len(train_set[i]))+ \" Validation set: \"+ str(len(validation_set[i]))+ \" Test set: \"+ str(len(test_set[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8190 images belonging to 39 classes.\n",
      "Found 1755 images belonging to 39 classes.\n",
      "Found 1755 images belonging to 39 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_data = train_datagen.flow_from_directory(os.path.join(dataset_path, 'training_set'),\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "validation_data = validation_datagen.flow_from_directory(os.path.join(dataset_path, 'validation_set'),\n",
    "                                            target_size = (64,64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(os.path.join(dataset_path, 'test_set'),\n",
    "                                            target_size = (64,64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (64,64,3), activation= 'relu'))\n",
    "BatchNormalization()\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "BatchNormalization()\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 39, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "256/256 [==============================] - 84s 326ms/step - loss: 2.9737 - acc: 0.1743 - val_loss: 2.5263 - val_acc: 0.2912\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - 75s 294ms/step - loss: 2.3368 - acc: 0.3391 - val_loss: 1.9557 - val_acc: 0.4154\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - 75s 292ms/step - loss: 1.8738 - acc: 0.4528 - val_loss: 1.6401 - val_acc: 0.5202\n",
      "Epoch 4/30\n",
      "256/256 [==============================] - 73s 287ms/step - loss: 1.6044 - acc: 0.5170 - val_loss: 1.4338 - val_acc: 0.5977\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - 76s 296ms/step - loss: 1.3844 - acc: 0.5805 - val_loss: 1.2887 - val_acc: 0.6313\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - 81s 315ms/step - loss: 1.2490 - acc: 0.6109 - val_loss: 1.2010 - val_acc: 0.6450\n",
      "Epoch 7/30\n",
      "256/256 [==============================] - 78s 306ms/step - loss: 1.1226 - acc: 0.6514 - val_loss: 1.1602 - val_acc: 0.6644\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - 74s 291ms/step - loss: 1.0418 - acc: 0.6812 - val_loss: 1.0431 - val_acc: 0.6963\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - 74s 288ms/step - loss: 0.9352 - acc: 0.7038 - val_loss: 0.9673 - val_acc: 0.7145\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - 82s 320ms/step - loss: 0.8598 - acc: 0.7320 - val_loss: 0.9569 - val_acc: 0.7356\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - 75s 294ms/step - loss: 0.8127 - acc: 0.7410 - val_loss: 0.9926 - val_acc: 0.7214\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - 75s 291ms/step - loss: 0.7607 - acc: 0.7606 - val_loss: 0.8921 - val_acc: 0.7504\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - 74s 291ms/step - loss: 0.7221 - acc: 0.7696 - val_loss: 0.9139 - val_acc: 0.7442\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - 74s 290ms/step - loss: 0.6784 - acc: 0.7850 - val_loss: 0.9406 - val_acc: 0.7390\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - 75s 294ms/step - loss: 0.6449 - acc: 0.8005 - val_loss: 0.9141 - val_acc: 0.7538\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - 75s 293ms/step - loss: 0.6131 - acc: 0.8054 - val_loss: 0.8249 - val_acc: 0.7863\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - 81s 318ms/step - loss: 0.5723 - acc: 0.8144 - val_loss: 0.8819 - val_acc: 0.7709\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - 76s 296ms/step - loss: 0.5412 - acc: 0.8237 - val_loss: 0.8363 - val_acc: 0.7795\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - 76s 295ms/step - loss: 0.5234 - acc: 0.8284 - val_loss: 0.8592 - val_acc: 0.7766\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - 76s 296ms/step - loss: 0.4980 - acc: 0.8370 - val_loss: 0.8535 - val_acc: 0.7852\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - 74s 289ms/step - loss: 0.4729 - acc: 0.8479 - val_loss: 0.8679 - val_acc: 0.7892\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - 75s 291ms/step - loss: 0.4461 - acc: 0.8531 - val_loss: 0.8187 - val_acc: 0.7761\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - 85s 330ms/step - loss: 0.4382 - acc: 0.8558 - val_loss: 0.8139 - val_acc: 0.7915\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - 83s 324ms/step - loss: 0.4284 - acc: 0.8571 - val_loss: 0.8835 - val_acc: 0.7835\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - 81s 318ms/step - loss: 0.4220 - acc: 0.8607 - val_loss: 0.8636 - val_acc: 0.7869\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - 68s 264ms/step - loss: 0.3868 - acc: 0.8747 - val_loss: 0.8065 - val_acc: 0.8103\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - 59s 230ms/step - loss: 0.3655 - acc: 0.8784 - val_loss: 0.8159 - val_acc: 0.8046\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - 59s 231ms/step - loss: 0.3738 - acc: 0.8746 - val_loss: 0.7737 - val_acc: 0.8120\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - 59s 229ms/step - loss: 0.3759 - acc: 0.8775 - val_loss: 0.8108 - val_acc: 0.7954\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - 60s 235ms/step - loss: 0.3494 - acc: 0.8873 - val_loss: 0.8681 - val_acc: 0.8051\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit_generator(training_data,\n",
    "                                  steps_per_epoch= math.ceil(training_data.n/training_data.batch_size),\n",
    "                                  epochs=30,\n",
    "                                  validation_data= validation_data,\n",
    "                                  validation_steps= math.ceil(validation_data.n/validation_data.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x205a1ed97f0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set : 0.8712643680901363\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = classifier.evaluate_generator(test_data, math.ceil(test_data.n / test_data.batch_size))\n",
    "print(\"Accuracy on test set : {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.8643678154068432\n"
     ]
    }
   ],
   "source": [
    "validation_loss, validation_accuracy = classifier.evaluate_generator(validation_data, math.ceil(validation_data.n / validation_data.batch_size))\n",
    "print(\"Accuracy on validation set: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2d4ba8232067>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "classifier_json = classifier.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(classifier_json)\n",
    "\n",
    "classifier.save_weights(\"model.h5\")\n",
    "print(\"Model saved to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\91876\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print('Loaded model from disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 39)                5031      \n",
      "=================================================================\n",
      "Total params: 172,007\n",
      "Trainable params: 172,007\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = cv2.waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "i= 10\n",
    "while True:\n",
    "    check, frame = webcam.read()\n",
    "    cv2.imshow(\"Capturing\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    x,y,w,h = 0,0,300,300\n",
    "    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "    roi = frame[y:y+h, x:x+w]\n",
    "    cv2.imshow(\"Capturing\", frame)\n",
    "    cv2.imwrite(filename='Images\\\\saved_img'+str(i)+'.jpg', img=roi)\n",
    "    cv2.waitKey(3000)\n",
    "    i += 1 \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "del webcam\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "cat_dir = \"Images\"\n",
    "cat_files = os.listdir(cat_dir)\n",
    "\n",
    "for file in cat_files:\n",
    "    image = cv2.imread(os.path.join(cat_dir, file))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    src = cv2.Canny(blurred, 10, 150)\n",
    "    dest = os.path.join(cat_dir, file)\n",
    "    im = Image.fromarray(src)\n",
    "    im.save(dest)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMRBLHA\n"
     ]
    }
   ],
   "source": [
    "cat_dir = \"Images\"\n",
    "cat_files = os.listdir(cat_dir)\n",
    "sentence = ''\n",
    "for i in cat_files:\n",
    "    img = cv2.imread(os.path.join(cat_dir, i))\n",
    "#     plt.imshow(img)\n",
    "    dims = (64,64)\n",
    "    img1 = cv2.resize(img, dims, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    image = img1/255\n",
    "    test_image = np.expand_dims(image, axis = 0)\n",
    "    \n",
    "    result = loaded_model.predict(test_image)\n",
    "#   print(result)\n",
    "    labels = np.argmax(result, axis=-1)  \n",
    "    if labels[0] == 0:\n",
    "        sentence += '0'\n",
    "    elif labels[0] == 1:\n",
    "        sentence += '1'\n",
    "    elif labels[0] == 2:\n",
    "        sentence += '2'\n",
    "    elif labels[0] == 3:\n",
    "        sentence += '3'\n",
    "    elif labels[0] == 4:\n",
    "        sentence += '4'\n",
    "    elif labels[0] == 5:\n",
    "        sentence += '5'\n",
    "    elif labels[0] == 6:\n",
    "        sentence += '6'\n",
    "    elif labels[0] == 7:\n",
    "        sentence += '7'\n",
    "    elif labels[0] == 8:\n",
    "        sentence += '8'\n",
    "    elif labels[0] == 9:\n",
    "        sentence += '9'\n",
    "    elif labels[0] == 10:\n",
    "        sentence += 'A'\n",
    "    elif labels[0] == 11:\n",
    "        sentence += 'B'\n",
    "    elif labels[0] == 12:\n",
    "        sentence += 'C'\n",
    "    elif labels[0] == 13:\n",
    "        sentence += 'D'\n",
    "    elif labels[0] == 36:\n",
    "        sentence = sentence[:-1]\n",
    "    elif labels[0] == 14:\n",
    "        sentence += 'E'\n",
    "    elif labels[0] == 15:\n",
    "        sentence += 'F'\n",
    "    elif labels[0] == 16:\n",
    "        sentence += 'G'\n",
    "    elif labels[0] == 17:\n",
    "        sentence += 'H'\n",
    "    elif labels[0] == 18:\n",
    "        sentence += 'I'\n",
    "    elif labels[0] == 19:\n",
    "        sentence += 'J'\n",
    "    elif labels[0] == 20:\n",
    "        sentence += 'K'\n",
    "    elif labels[0] == 21:\n",
    "        sentence += 'L'\n",
    "    elif labels[0] == 22:\n",
    "        sentence += 'M'\n",
    "    elif labels[0] == 23:\n",
    "        sentence += 'N'\n",
    "    elif labels[0] == 37:\n",
    "        sentence += ''\n",
    "    elif labels[0] == 24:\n",
    "        sentence += 'O'\n",
    "    elif labels[0] == 25:\n",
    "        sentence += 'P'\n",
    "    elif labels[0] == 26:\n",
    "        sentence += 'Q'\n",
    "    elif labels[0] == 27:\n",
    "        sentence += 'R'\n",
    "    elif labels[0] == 28:\n",
    "        sentence += 'S'\n",
    "    elif labels[0] == 38:\n",
    "        sentence += ' '\n",
    "    elif labels[0] == 29:\n",
    "        sentence += 'T'\n",
    "    elif labels[0] == 30:\n",
    "        sentence += 'U'\n",
    "    elif labels[0] == 31:\n",
    "        sentence += 'V'\n",
    "    elif labels[0] == 32:\n",
    "        sentence += 'W'\n",
    "    elif labels[0] == 33:\n",
    "        sentence += 'X'\n",
    "    elif labels[0] == 34:\n",
    "        sentence += 'Y'\n",
    "    elif labels[0] == 35:\n",
    "        sentence += 'Z'\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter:\n",
      "1 for English\n",
      "2 for Kannada\n",
      "3 for Hindi\n",
      "4 for Telugu\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter:\")\n",
    "print(\"1 for English\")\n",
    "print(\"2 for Kannada\")\n",
    "print(\"3 for Hindi\")\n",
    "print(\"4 for Telugu\")\n",
    "lang = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lang == '1':\n",
    "    language = 'en'\n",
    "elif lang == '2':\n",
    "    language = 'kn'\n",
    "elif lang == '3':\n",
    "    language = 'hi'\n",
    "elif lang == '4':\n",
    "    language = 'te'\n",
    "else:\n",
    "    print('Please enter a proper value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_trans_new import google_translator\n",
    "translator = google_translator()\n",
    "result = translator.translate(sentence.lower(), lang_tgt=language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambelha \n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = gTTS(text=result, lang=language, slow=False, tld='com')\n",
    "output.save('speech.mp3')\n",
    "\n",
    "os.system(\"start speech.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
